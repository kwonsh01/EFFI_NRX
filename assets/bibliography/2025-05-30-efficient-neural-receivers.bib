@misc{pruning,
  title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks}, 
  author={Jonathan Frankle and Michael Carbin},
  year={2019},
  eprint={1803.03635},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1803.03635}, 
}

@inproceedings{movement_pruning,
 author = {Sanh, Victor and Wolf, Thomas and Rush, Alexander},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {20378--20389},
 publisher = {Curran Associates, Inc.},
 title = {Movement Pruning: Adaptive Sparsity by Fine-Tuning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/eae15aabaa768ae4a5993a8a4f4fa6e4-Paper.pdf},
 volume = {33},
 year = {2020}
}

@online{pruning_rt,
  author = {Jeff Pool, Abhishek Sawarkar and Jay Rodge},
  title = {Accelerating Inference with Sparsity Using the NVIDIA Ampere Architecture and NVIDIA TensorRT},
  year = 2021,
  url = {https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/},
  urldate = {2025-04-06}
}

@INPROCEEDINGS{tfmvp,
  author={Yoo, Eunji and Park, Gunho and Min, Jung Gyu and Jung Kwon, Se and Park, Baeseong and Lee, Dongsoo and Lee, Youngjoo},
  booktitle={2023 60th ACM/IEEE Design Automation Conference (DAC)}, 
  title={TF-MVP: Novel Sparsity-Aware Transformer Accelerator with Mixed-Length Vector Pruning}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  keywords={Semiconductor device modeling;Analytical models;Design automation;Transformers;CMOS technology;Energy efficiency;Hardware;Algorithm-hardware co-optimization;Model Compression;Sparsity-aware transformer accelerator},
  doi={10.1109/DAC56929.2023.10247799}
}

@misc{nvidia_sparse_tensor_core,
      title={Accelerating Sparse Deep Neural Networks}, 
      author={Asit Mishra and Jorge Albericio Latorre and Jeff Pool and Darko Stosic and Dusan Stosic and Ganesh Venkatesh and Chong Yu and Paulius Micikevicius},
      year={2021},
      eprint={2104.08378},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2104.08378}, 
}